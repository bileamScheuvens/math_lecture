\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{amssymb, amsmath, amsthm, amsfonts, algorithmic, algorithm, graphicx}
\usepackage{color}
\usepackage{bbm}
\usepackage[dvipsnames]{xcolor} 
\usepackage[colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{array}
\usepackage{ifthen}
\usepackage{mathtools}

\renewcommand{\baselinestretch}{1.1}
\setlength{\topmargin}{-3pc}
\setlength{\textheight}{8.5in}
\setlength{\oddsidemargin}{0pc}
\setlength{\evensidemargin}{0pc}
\setlength{\textwidth}{6.5in}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{question}[theorem]{Question}
\newtheorem{result}[theorem]{Result}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}[theorem]{Assumption}
\numberwithin{equation}{section}

\def \endprf{\hfill {\vrule height6pt width6pt depth0pt}\medskip}
\renewenvironment{proof}{\noindent {\bf Proof} }{\endprf\par}

% Notational convenience,
% real numbers 
\newcommand{\R}{\mathbb{R}}  
% Expectation operator
\DeclareMathOperator*{\E}{\mathbb{E}}
% Probability operator
\DeclareMathOperator*{\Prob}{\mathbb{P}}
\renewcommand{\Pr}{\Prob}

% You may define additional macros here.
\newcommand{\unita}{\begin{pmatrix} 1\\0\end{pmatrix}}
\newcommand{\unitb}{\begin{pmatrix} 0\\1\end{pmatrix}}
\newcommand{\gramint}{\int_{-1}^1}
\newcommand{\limn}{\underset{n\rightarrow \infty}{lim}}
\newcommand{\epix}{e^{\pi-x}}


\begin{document}

\begin{center}
    \sc ML 4101: Mathematics for Machine Learning --- Fall 24
\end{center}

\noindent Friederike Horn \& Bileam Scheuvens

Justify all your claims.
\section*{Exercise 1 (Recursive Sequences)}
\begin{enumerate}
\item[a)]{
  Let $(a_n)n\in N$ be a sequence in $\mathbb{R}$. Prove that if $a_n$ is monotone increasing and has an upper bound, then it converges to its supremum.
  }
\item[b)]{
    Prove that the recursive sequence $a_{n+1} = \sqrt{a_n + 2}$ with $a_n = 0$ converges and determine its limit.
  }
\end{enumerate}
\subsection*{Solution}
\begin{enumerate}
\item[a)]{
    Let $U$ be some upper bound such that $a_n \leq a_{n+1} \leq U$. If an upper bound exists, then logically a lowest upper bound must exist, which we call supremum.
  It follows that $|U-a_n| \geq |U - a_{n+1}|$ and therefore $\exists U' \leq U$ such that for every $\epsilon > 0$ $|S-a_n| < \epsilon$. If it weren't the case, then there would be a lesser bound which satisfies this, but by construction this cannot happen, as this bound would then be supremum and we would've chosen it as $U'$ instead.
  }
\item[b)]{
    The sequence can easily be shown to be monotonically increasing:
    The base case is satisfied as $a_0 = 0 < a_1 = \sqrt{2}$ and the derivative of $\sqrt{n+2}$ is positive ($\frac{1}{2\sqrt{x+2}}$).
    Additionally the sequence is bounded since for any $x > 2$, $\sqrt{x+2}< x$. This can be seen for the example $x=4$, since $\sqrt{6} < 4$ violating the proven property of monotonic increase.
    Since we know from a) this implies a limit exists, for sufficiently large $n$, it holds that $\underset{n\rightarrow \infty}{lim} a_{n+1} = \underset{n\rightarrow \infty}{lim} a_{n+2}$.
    \begin{align*}
      \limn a_n &= \limn \sqrt{a_n+2}\\
      \limn a_n^2 &= \limn a_n+2\\
      \limn a_n^2 -a_n -2 &= 0\\
    \end{align*}
    This has Roots $\frac{1}{2} +- \frac{3}{2} = 2, -1$.
    We discard the negative root and obtain $L = 2$.


  }

\end{enumerate}

\section*{Exercise 2 (Continuity)}
\begin{enumerate}
\item[a)]{
    Prove that every Lipschitz continous function is uniformly continous.
  }
\item[b)]{
    Prove that $g: x \mapsto x^2$ is not uniformly continous.
  }
\item[c)]{
    Prove that $h: x \mapsto \sqrt{x}$ is uniformly continous but not Lipschitz continous.
  }
\end{enumerate}
\subsection*{Solution}
\begin{enumerate}
\item[a)]{
    Since $d(f(x),f(y)) \leq L \cdot d(x,y)$ from Lipschitz continuity and we require $that  \exists \delta = d(x,y)$ such that $d(f(x),f(y)) < \epsilon$, we can choose $\delta$ as $\frac{\epsilon}{L}$. Then:
    $$d(f(x), f(x+\delta)) < L \cdot \delta = L \frac{\epsilon}{L} = \epsilon$$

  }
\item[b)]{
    For any $\delta$,
    \begin{align*}
      d(g(x), g(x + \delta)) &= x^2 - x^2 + 2x\delta + \delta^2\\
                           &= 2x\delta + \delta^2\\
    \end{align*}
    Since this is dependent on x on a term that dominates in the limit, for large x we cannot choose $\delta$ appropriately to get this distance arbitrarily small.
  }
\item[c)]{
    $h$ is Lipschitz continous as:
    FILL IN!

      However as $h'(x) = \frac{1}{2\sqrt{x}}$, $\underset{x\rightarrow 0}{lim} \; h'(x) = \infty$, thus $\nexists L$.
  }

\end{enumerate}
\section*{Exercise 3 (Uniform Convergence)}
\begin{enumerate}
\item[a)]{
    Analyze whether $f_n: x\mapsto \frac{1}{n}sin(nx)$ and $g: x \mapsto x + \frac{x}{n}cos(x)$ converge. If so, state limit and prove whether convergence is uniform.
  }
\item[b)]{
    Consider a sequence of functions $f_n: \mathcal{D} \rightarrow \mathbb{R}$ on a finite set $\mathcal{D}$ that converges pointwise. Prove that $f_n$ converges uniformly.
  }


\vspace{0.5cm}
  \hspace{-0.8cm}
  Consider a sequence of functions $f_n: [a,b]$ which are Lipschitz continous with the same $L > 0$. Assume that this sequence converges pointwise.
\item[c)]{
    Prove that $f$ is also Lipschitz continous with same $L$.
  }
\item[d)]{
    Prove that $f_n$ converges uniformly to $f$.
  }
\end{enumerate}


\subsection*{Solution}
\begin{enumerate}
\item[a)]{
    $$\limn \frac{sin(nx)}{n} = 0$$
    Thus the function sequences converges pointwise to $f(x) = 0$.
    For uniform convergence we require $|f_n - f| < \epsilon$:
    $$\limn |\frac{sin(nx)}{n} - 0|$$
    Since $sin(nx) \leq 1$:
    $$ \leq \limn |\frac{1}{n}|$$
    which is $\leq \epsilon$ for $n\geq \epsilon$, proving uniform convergence.

    For the second sequence:
    $$\limn x + \frac{x cos(x)}{n} = x$$
    Since the second term tends to 0, while $x$ is unaffected.
    Investigating uniform convergence:
    $$\limn |x + \frac{x cos(x)}{n} - x| < \epsilon$$
    $$\limn |\frac{x cos(x)}{n}| < \epsilon$$
    Since $cos(x) \leq 1$, $x cos(x) \leq x$ but otherwise unbounded. Therefore for any $n$ we can choose $x > \frac{n\epsilon}{cos(x)}$ to achieve a function value not $\epsilon$ close and the sequence does not converge uniformly.

  }
\item[b)]{
  }
\item[c)]{
    Since $f_n$ is Lipschitz continous, for any deviation $\delta$ we know $d(f_n(x), f_n(x+\delta)) \leq L\delta$ for some distance metric $d$ with $d(\delta) = \delta$.
    Since $f_n$ converges pointwise, $\limn |f_n - f| = 0$.
    It immediately follows that $d(f(x) - f(x+\delta)) \leq L\delta + 2\cdot 0 = L\delta$, proving Lipschitz continuity.
  }
\item[d)]{
  }
\end{enumerate}


\section*{Exercise 4 (Power and Taylor Series)}


\begin{enumerate}
\item[a)]{
    Determine the radius of convergence of:
    $$\sum_{j=1}^{\infty} \frac{j^2}{2^j}x^j \text{ and }\sum_{j=1}^{\infty} 3^j {x^j}^2$$
  }
\item[b)]{
    Compute the Taylor polynomial of $f: x \mapsto e^{\pi -x} sin(x)$ with $a=0$ of degree $3$ and the corresponding Lagrange remainder.
  }
\item[c)]{
    Prove that $f$ from b) is equal to its Taylor series.
  }
\end{enumerate}

\subsection*{Solution}
\begin{enumerate}
  \item[a)]{
       $$\underset{j\rightarrow \infty}{lim} \frac{\frac{j^2}{2^j}}{\frac{(j+1)^2}{2^{j+1}}}$$
       $$=\underset{j\rightarrow \infty}{lim} \frac{2^j 2 \frac{j^2}{2^j}}{j^2 + 2j + 1}$$
       $$=\underset{j\rightarrow \infty}{lim} \frac{2 j^2}{j^2 + 2j + 1}$$
       $$\approx \underset{j\rightarrow \infty}{lim} \frac{2 j^2}{j^2} = 2 = r$$

       Second series:
       $$\sum_{j=1}^{\infty} 3^j x^{2j}$$
       $$=\sum_{i=1}^{\infty} 3^{i/2} x^i$$
       $$\underset{i\rightarrow \infty}{lim} \frac{3^{i/2}}{3^{(i+1)/2}}$$
       $$=\underset{i\rightarrow \infty}{lim} \frac{\sqrt{3^i}}{\sqrt{3}\sqrt{3^i}}$$
       $$=\frac{1}{\sqrt{3}} = r$$
    }
  \item[b)]{
    \begin{align*}
      f(x) &= \epix sin(x)\\
      f^i(x) &= \epix (cos(x) - sin(x))\\
      f^{ii}(x) &= 2\epix cos(x)\\
      f^{iii}(x) &= 2\epix (sin(x) + cos(x))\\
      f^{iv}(x) &= -4\epix sin(x)\\
    \end{align*}

    \begin{align*}
      T_3(x,\pi) &= \sum_{k=0}^3 \frac{f^{(k)}(\pi)}{k!}(x-\pi)^k\\
                 &= \frac{e^0 sin(\pi)}{0!}(x-\pi)^0 + \frac{e^0 (cos(\pi) - sin(\pi))}{1!}(x-\pi)^1 + \frac{2e^0 cos(\pi)}{2!}(x-\pi)^2 + \frac{2e^0 (cos(\pi) - sin(\pi))}{3!}(x-\pi)^3\\
                 &= \frac{0}{0!}1 + \frac{ (1 - 0)}{1}(x-\pi)^1 + \frac{2\cdot 1}{2}(x-\pi)^2 + \frac{2 (1 - 0)}{6}(x-\pi)^3\\
                 &= (x-\pi)^1 + (x-\pi)^2 + \frac{1}{3}(x-\pi)^3\\
    \end{align*}
    \begin{align*}
      R_3(x,\pi) &= \frac{f^{(4)}(\xi)}{4!}(x-pi)^4\\
                 &= \frac{8e^{\pi-\xi}sin(\xi)}{4!}(x-\pi)^4\\
                 &= \frac{e^{\pi-\xi}sin(\xi)}{3}(x-\pi)^4\\
    \end{align*}
    Where $e^{\pi-\xi}$ is at most $e^\pi$ for $\xi = 0$ and $sin(\xi)$ is maximally $1$ for $\xi = \frac{\pi}{2}$ yielding an upper bound on the error as $\frac{e^pi}{3}(x-\pi)^4$.

    }
  \item[c)]{
      The taylor series is the taylor polynomial of degree $\infty$.
      Since the denominator of the Lagrange error terms is factorial, thus growing faster than the at most exponential remaining terms, the relative error approaches zero, converging to the original function and therefore the Taylor series.
    }
\end{enumerate}

\end{document}
